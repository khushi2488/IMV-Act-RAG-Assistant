"""
ingest_faiss.py
This script creates a FAISS vector database from your MVA_Data.md file
Run this ONCE before running the Streamlit app
"""

from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain_core.documents import Document
import os

print("ğŸ”„ Starting data ingestion process...")

# Step 1: Load the MVA data from markdown file (WITHOUT document loader)
print("ğŸ“„ Loading MVA_Data.md...")
try:
    # Direct file reading - no document loader needed!
    with open("MVA_Data.md", 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Create a Document object manually
    documents = [Document(page_content=content, metadata={"source": "MVA_Data.md"})]
    print(f"âœ… Loaded {len(documents)} document(s)")
    print(f"   File size: {len(content)} characters")
except FileNotFoundError:
    print("âŒ Error: MVA_Data.md not found!")
    print("   Make sure the file exists in the current directory.")
    exit(1)
except Exception as e:
    print(f"âŒ Error loading file: {e}")
    exit(1)

# Step 2: Split documents into smaller chunks
print("âœ‚ï¸  Splitting text into chunks...")
text_splitter = CharacterTextSplitter(
    separator='-->',  # Split at MVA section markers
    is_separator_regex=False,
    chunk_size=500,
    chunk_overlap=50  # Add overlap to maintain context
)
texts = text_splitter.split_documents(documents)
print(f"âœ… Created {len(texts)} text chunks")

# Step 3: Load embedding model
print("ğŸ¤– Loading embedding model (BAAI/bge-base-en)...")
print("   â³ This may take a few minutes on first run (downloading 440MB model)...")
try:
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-base-en",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    print("âœ… Embedding model loaded")
except Exception as e:
    print(f"âŒ Error loading embedding model: {e}")
    print("ğŸ’¡ Try: pip install sentence-transformers torch")
    exit(1)

# Step 4: Create FAISS vector store
print("ğŸ’¾ Creating FAISS vector database...")
print("   â³ This may take 1-2 minutes...")
try:
    vectorstore = FAISS.from_documents(
        documents=texts,
        embedding=embeddings
    )
    print("âœ… FAISS vector database created")
except Exception as e:
    print(f"âŒ Error creating FAISS index: {e}")
    print("ğŸ’¡ Try: pip install faiss-cpu")
    exit(1)

# Step 5: Save to disk
print("ğŸ’¿ Saving to disk...")
try:
    vectorstore.save_local("faiss_mva_index")
    print("âœ… FAISS index saved to 'faiss_mva_index' folder")
except Exception as e:
    print(f"âŒ Error saving index: {e}")
    exit(1)

print("\n" + "="*50)
print("ğŸ‰ DATA INGESTION COMPLETE!")
print("="*50)
print(f"ğŸ“Š Statistics:")
print(f"   - Documents loaded: {len(documents)}")
print(f"   - Text chunks created: {len(texts)}")
print(f"   - Embedding model: BAAI/bge-base-en (768 dimensions)")
print(f"   - Index location: faiss_mva_index/")
print("\nğŸ“Œ Next step:")
print("   streamlit run streamlit_app.py")
print("="*50)